# 動体検知プログラム (Motion-Detection-App)

本アプリは OpenCV を用いた**動体検知の学習用**プログラムです。処理はシンプルですが、実務でも定番のパイプライン（背景差分 → 二値化 → 形態学的処理 → 輪郭抽出 → 事象判定）をひと通り体験できます。<br>
※ 実装詳細はコード内コメント、理論は本 README の「理論的背景」を参照してください。

**動作環境**: Python / OpenCV (`opencv-python`)

---

## プロジェクト構成

```
Motion/
├── src/
│   └── Motion-Detection-App.py  # メインアプリケーション
├── .gitignore                   # Gitの無視ファイル設定
├── README.md                    # このファイル
└── requirements.txt             # 依存ライブラリ
```

## セットアップ方法

1.  **リポジトリをクローン**
    ```bash
    git clone <repository-url>
    cd Motion
    ```

2.  **仮想環境の作成（推奨）**
    ```bash
    python -m venv venv
    source venv/bin/activate  # macOS/Linux
    venv\Scripts\activate     # Windows
    ```

3.  **依存ライブラリのインストール**
    ```bash
    pip install -r requirements.txt
    ```

## 実行方法

以下のコマンドでプログラムを実行します。Webカメラが起動し、動体検知が開始されます。

`Esc`キーでプログラムを終了します。

```bash
python src/Motion-Detection-App.py
```

---

## 理論的背景

このプログラムは、カメラに映る映像から「動き」を検出するために、一連の画像処理ステップ（パイプライン）を実行します。パイプラインの目的は、フレーム（映像の1コマ）ごとに「意味のある変化」だけを抽出し、それを「1回のイベント」としてカウントすることです。

```
[入力フレーム] → (1) 背景差分 → (2) 二値化 → (3) ノイズ除去 → (4) 輪郭抽出 → [動き判定] → (5) イベント正規化 → [カウント]
```

以下に、各ステップの詳細を解説します。

---

### 1. 背景モデルの構築と差分抽出

まず、「静的な背景」がどのようなものかを学習し、それとの比較によって「動き」をあぶり出します。

-   **背景の学習**:
    > `cv2.accumulateWeighted` を使い、過去のフレームの情報を少しずつ取り込みながら、**指数移動平均（EMA）**と呼ばれる手法で背景モデルを更新し続けます。これにより、照明のゆっくりとした変化など、環境の変化に追従できます。
    >
    > `LEARN_RATE` (`α`) は学習率を制御するパラメータです。
    > - **高い値**: 最新のフレームを強く反映し、環境変化に素早く適応しますが、ゆっくり動く物体は背景に溶け込んでしまいます。
    > - **低い値**: 背景を安定させますが、急な照明変化に対応しにくくなります。

-   **差分の計算**:
    > 現在のフレームと学習済みの背景モデルとの間で**差分**（`cv2.absdiff`）を取ります。差分が大きいピクセルは、「背景からの変化」＝「動きの候補」となります。

---

### 2. 前処理と二値化

差分画像にはノイズが多く含まれるため、動きの領域を明確にするための処理を行います。

-   **平滑化（ノイズ除去）**:
    > `cv2.GaussianBlur` を用いて画像をぼかし、高周波ノイズ（ランダムなピクセルのちらつき等）を低減します。これにより、後の処理で誤検出が起こりにくくなります。

-   **二値化（白黒画像への変換）**:
    > **大津の二値化**（`cv2.THRESH_OTSU`）という手法を使い、差分画像を「動きがあった領域（白）」と「動きがなかった領域（黒）」の2値に分けます。この手法は、画像ヒストグラムから背景と前景を最もよく分離するしきい値を自動的に決定してくれるため、非常に便利です。

---

### 3. 形態学的処理によるノイズ除去

二値化された画像には、まだ小さな孤立点（ノイズ）や、逆に検出したい領域内の穴が存在することがあります。これらを整理し、輪郭を綺麗にします。

-   **開演算 (Opening)**:
    > `cv2.morphologyEx` の `MORPH_OPEN` を使用します。これは、画像を一度「縮小（侵食）」させて細かいノイズを除去し、その後「膨張」させて元のサイズに戻す処理です。これにより、**白点のノイズを取り除く**効果があります。

-   **膨張 (Dilation)**:
    > `cv2.dilate` を使い、検出された白い領域を少し太らせます。これにより、**領域内の小さな穴を埋めたり、途切れた部分を連結したりする**効果があります。

---

### 4. 輪郭抽出と面積によるフィルタリング

整理された二値画像から、「動き」と判断できるまとまった領域（輪郭）を見つけ出します。

-   **輪郭の検出**:
    > `cv2.findContours` を使い、白い領域の境界線（輪郭）をすべて検出します。

-   **面積による選別**:
    > 検出された各輪郭の面積（`cv2.contourArea`）を計算し、`AREA_MIN` で指定された**最小面積よりも小さい輪郭はノイズとみなし、無視します**。これにより、虫や影のちらつきといった小さな変化を「動き」としてカウントしないようにします。

---

### 5. イベント判定（状態機械による正規化）

フレームごとに「動きあり/なし」を判定するだけでは、物体が少し動くだけで何度もカウントしてしまう「過剰カウント」が発生します。これを防ぐため、時間的な連続性を考慮した**状態機械**を用いて、「一連の動き」を「1回のイベント」として正規化します。

-   **イベント開始条件**:
    > 「動きあり」のフレームが `PERSIST_FRAMES` の枚数だけ**連続**した場合に、初めて**イベント開始**と判断し、カウントを1増やします。

-   **イベント終了条件**:
    > 「動きなし」のフレームが `QUIET_FRAMES` の枚数だけ**連続**した場合に、**イベント終了**と判断します。

-   **不感帯の設定**:
    > 一度のイベントが終わった後、`MIN_EVENT_GAP_S` で指定された秒数の間は、新たなイベントを検出しない**不感帯**を設けます。これにより、同じ動きが二重にカウントされるのを防ぎます。